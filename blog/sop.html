<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Statement of Purpose</title>
    <link rel="stylesheet" href="../css/sop.css">
    <!-- <link href="https://fonts.googleapis.com/css2?family=Courier+Prime:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet"> -->
</head>
<body>
    <div class="button-row">
        <button id="contrast" class="cont-inv" onclick="toggleContrast()">contrast</button>
        <button id="invmode" class="cont-inv" onclick="toggleInvert()">invert</button>
    </div>

    <article>
        <h1> Statement of purpose </h1>
        <h2 style="align-items: left;">What?</h2>
        <p>
            Besides the general definition of a statement of purpose (see: <a href="https://users.ece.cmu.edu/~mabdelm/statement-of-purpose-tips.html">this</a>) an SoP involves showing
            <ul>
                <li>that you can do (and like to do!) research in the first place.</li>
                <li>what your research-focused goals are.</li>
                <li>why a PhD is the best fit for you.</li>
            </ul>
            To this end, I tried to incorporate these elements into my SoP by demonstrating my:
            <ul>
                <li>Learnings from my projects: Specifically the part of my profile that just cannot be explained through my CV, transcripts, or publications.</li>
                <li>Initiative: Specifically, where I took charge, or started a research initiative, such as starting a team for the Amazon Challenge, or taking my Microsoft project forward at CMU with my own ideas.</li>
                <li>How (some of) my past projects inform me of my future goals: There's a reason why I believe AI security is important; I incorporate some elements of what brought in this belief.</li>
            </ul>
            In my experience, the last part was surprisingly the hardest to refine, and needed multiple rounds of review from my advisors and peers; I had way too much to share without a cohesive narrative. Looking back, I realize my statement reads quite boring and maybe as though I'm slightly annoyed with it - but this was a conscious choice on my part. I didn't want the admissions committee to be enamoured by my life story, but to simply see that I can do research and am a good fit for their program. 
        </p>
        <h2 style="align-items: left;">My annotated statement of purpose</h2>
        <p>
            Below is my annotated statement of purpose for graduate school applications. I've added comments to explain the reasoning behind each section.
            I would also encourage you to check out these resources:
            <ol>
                <li> Saujas' <a href="https://saujasv.github.io/phd-applications">annotated statement and other resources</a></li>
                <li> Steven Kolawole's <a href="https://stevenkolawole.medium.com/the-road-to-phd-ii-my-approach-to-the-applications-4bbf5293d02b"> approach to his applications</a></li>
                <li> Shaily's <a href="https://github.com/shaily99/advice">graduate school resources (just a reminder not to procrastinate on these resources!!)</a></li>
                <li> Diddee's <a href="https://harshitadd.netlify.app/advice/">advice on her experience with applications</a></li>
            </ol>
            A few things to note here: 
            <ul>
                <li> All of these resources come from my friends/colleagues from LTI, CMU; a lot of advice that I'll be mentioning here comes from my time at the LTI. I'm now no longer at CMU, and I'm doing my PhD without a core focus in NLP, so some of this advice may not be applicable to all readers.</li>

                <li>I prefer using prescriptive language in my blogposts. This comes purely from <a href="https://web.mit.edu/curhan/www/docs/Articles/15341_Readings/Influence_Compliance/Markus_Kitayama_1991_Culture_and_the_self.pdf#page=6.25"> my own conditioning</a> -- However, none of these annotations are meant to be prescriptive how-to guides on writing SoPs; they're simply to provide my internal thought process of why I chose to do what I did, with the intent that it may help inform you in your own writing. </li>

                <li> Finally, this is my 1000-ish word SoP for PhD applications in the US. If you're applying to other kinds of programs (masters, PhDs in other countries), the structure and content of your SoP may differ significantly.</li>

            </ul>
            
            
        </p>
        <blockquote>
            I aim to pursue a Ph.D. at the intersection of Natural Language Processing (NLP), Safety, and Security. I am keen on going beyond chat-based interactions and exploring systems that are granted forms of agency. This interest stems from my realization that generative harms are
            not limited to chat interfaces or user-system interactions alone; when models can take actions, the potential for unintended consequences increases significantly. Below, I highlight my experiences surrounding AI safety, security and ethics that have shaped my research interests and led me to consider pursuing this problem.
        </blockquote>
        The aim of the first paragraph of my Statement was to clearly state my research topic, and the subproblems in which I'm looking to research on. I segue into the actual motivation behind considering this topic through my final lines ("I highlight my experiences")

        <blockquote>
            <b>Jailbreaking and LLM Safety:</b> As large language models get increasingly powerful in terms of their capabilities, they are also increasingly prone to causing harm to their users.
            This is something I quickly realized as a Research Fellow at Microsoft Turing - around late 2022, I discovered early on in a bug bash for our product, Bing Chat, that it exhibited surprisingly toxic generations when cleverly prompted to do so. While such prompts are
            established as jailbreaks, there was little analysis at the time that understood the extent and applicability of these harms. Hence, I initiated a project studying jailbreaks with my
            mentors, Prof. <b>Monojit Choudhury</b> and Prof. <b>Somak Aditya</b>, curating an ontology of jailbreak types, lexical categories, and their attacker’s intentions. Through this work, I
            uncovered that jailbreaks were further exacerbated when different alignment techniques were applied and upon scaling model parameters 
            To better capture attack success I further proposed a two-subject evaluation paradigm: whether model outputs are misaligned from
            the original task, and if attacker intents are satisfied. This work was published at LREC-CoLING 2024[1]. 
        </blockquote>
        Unlike what a lot of people do in their SoPs, I decided to use section headers to clearly demarcate my different research experiences. This is rather common in computer science SoPs, especially in empirical AI research, where people tend to work on several not-so-very chronologically connected research projects. <br/>
        
        The admissions committee primarily looks for:
        <ul>
            <li>What research problems have you worked on and how did they inform your goals? (advisor fit)</li>
            <li>What was your role in the project and your key contributions? (Evidence for independence and initiative, and other soft-skills)</li>
            <li>What did you learn from the project? (your technical and research proficiency and in some cases, personal growth)</li>
        </ul>
        I tried to answer these questions in each of my research experience sections by cutting all fluff and simply specifying my most informative research projects, what I did in them, and what I learned from them. <br/>
        <blockquote>    
            This was a great learning experience for me; I learned how to formalize an unfamiliar and understudied problem by defining a jailbreak 
            ontology, curating a dataset and evaluating models on multiple axes.
        </blockquote>
        When I mention that I specified what I learned from projects, I don't necessarily mean the technical learnings from my results alone! That would be simply a summary of the paper, or a rehash of my CV.
        What's more important is <a href="https://harshitadd.netlify.app/advice">deduplication</a>. My personal learnings and reflections cannot be specified in a paper or CV, so I decided to include them over here. 
        <blockquote>
            Realizing that most jailbreak methods focused solely on chat-based systems led me to explore broader threat models - I formed a team and secured a $250,000 grant to work on the Amazon Trusted AI Challenge - an attack-defense competition to develop and red-team
            Code LLMs. Advised by Prof. <b>Carolyn Rose</b> from the Language technologies institute (LTI) and Prof. <b>Michael Hilton</b> from Software and Societal System Department (S3D), CMU, I’m
            working on minimizing code-vulnerabilities, such as those from the Common Weakness Enumeration (CWEs) by leveraging code-vulnerability datasets such as the MITRE ATT&CK Python CWEs to develop strong attack vectors in a black-boxed setup.
        </blockquote>
        This paragraph is what caught the eye of most of my interviewers, as it mentioned two things - 
        (1) I was able to secure funding for a project, and (2) I was able to mobilize a team to work on a problem I cared about. Both of these are very important skills for an academic researcher, as you will invariably need to write grants and lead teams in your future career. <br/>
        A sidenote: while I was very authoritative in this paragraph, I eventually didn't lead this project for reasons beyond the scope of this blogpost. I made sure to clarify this change explicitly with my interviewers. However, it would have been better if I had worded this paragraph more carefully in anticipation of such changes. 
        <blockquote>
            <b>Future directions</b>: During my graduate studies, I wish to study threat models that aren’t restricted to toxic/harmful generation. While reviewing existing work for the Amazon Challenge, I noticed that singular defenses like circuit breakers [4] may not handle insecure
            code generation. Hence, it is necessary to have comprehensive security frameworks that can anticipate and mitigate unintended harmful actions by AI systems. Additionally, developing robust monitoring and evaluation systems [5] when multiple actors/agents are involved can add multiple layers of complexity to the problem.
        </blockquote>
        There are many ways to write about your future directions. I personally preferred to structure my future directions in a separate paragraph at the end of each of my research experience sections, as they were fairly disconnected and non-chronological. <br/> 
        My research directions are rather generic - I don't even specify concrete examples of the "threat models" I was mentioning! However, they're specific enough to show that I have a clear idea of what I want to research on. This kind of balance is rather crucial in an SoP; 
        a super generic direction (e.g. I want to work on AI alignment) is not very convincing and doesn't give you an edge, while a super specific direction (e.g. I want to study the effect of insecure code generation on industrial package development) may box you in to a very limited scope, pushing you away from potential advisors. <br/>
        A general tip here is to optimize for <i>recall</i> - though I wanted to work on AI Security, I considered applying to professors who were studying LLMs' dual use from the angle of social biases to as far as software development.
        <blockquote>
            <b>AI-Ethics; cultural representation harms, and generalizability</b>: AI systems have been known to misrepresent certain sections of society by directly undermining or failing to recognize their core values: I studied the detrimental nature of alignment methodologies on
            LLM’s ethical reasoning abilities in a position paper I led on value pluralism. I designed a framework, developing a systematic evaluation paradigm to evaluate the ethical reasoning
            capabilities of a language model, encompassing moral dilemmas over multiple granularities (EMNLP Findings, WiNLP Keynote 2023 [2]). This work advocated that LLMs should be
            value-neutral, and that value-alignment should occur at the application level. This project was my first introduction to interdisciplinary research, and it required that I studied moral
            frameworks surrounding the ethical triple theory, and to effectively communicate their subjective ideas amongst team members. 
            The results from this effort proved particularly interesting: LLMs hinted a western centric bias in their reasoning, and they were unable to
            adapt their outputs to user-provided policies. I wished to translate this philosophical position into a practically usable resource to measure this adaptability further.
        </blockquote>
        I <i>really</i> did not wish to explore this direction during my PhD - however, I still wanted to include it in my SoP to show that I had a breadth of research experiences, and that I was able to take initiative in different environments. In hindsight, my learnings are rather underwhelming here; this was a position paper on a topic I barely spent a year on, and for a contribution I had a very hard time appreciating. This paragraph served more as a <i>motivation</i> into my next research experience.
        <blockquote>
            When I entered CMU, I noticed work surrounding NLP and cultural studies borrowed frameworks that directly evaluated humans’ intrinsic moral values. However, an LLM
            deployed worldwide should largely be value neutral and should also be able to adapt to users from different backgrounds. Hence, in a project supervised by Prof. <b>Maarten Sap</b>, I designed
            a dataset, NormAd-Eti [3], to evaluate cultural adaptability of language models by contextualizing social situations, with coarse grained geographical information, and finer
            grained social norms. Through this framework, we encountered several key insights (1) language models indeed have a western-centric bias when contextualized with social norms,
            (2) this bias is amplified through value-alignment strategies. (C3NLP workshop @ ACL 2024; in review at NAACL 2025).
        </blockquote>
        This paragraph's main intent was to show that I translated my (well, tough-to-appreciate) framework into something more usable and concrete, and was able to publish it at a top-tier venue (NormAd eventually was accepted into NAACL-main as an oral session after two resubmissions). 
        Here I show best my independence as a researcher - I was able to maintain a consistent research direction even when I switched institutions, advisors, and research groups. I believe that while some projects may not directly inform you of your future goals, they can still be useful in showing your research skills to the adminssions committee. <br/>
        One key thing to note here is that you do not need to include every single research experience you've had.Furthermore, you do not need to explain your life's story and how you transformed over the course of a few years -- I also have some minor research experience on multilingual NLP; but I chose to exclude it as it didn't add much value to my overall narrative.
        <br/>
        <blockquote> 
            <b>Future Directions</b>: The findings uncovered by NormAd makes me more curious about other biases related to non-chat setups that are exacerbated during the value alignment
            stage. Furthermore, I believe multi-agent setups can offer a different perspective on biases which chat based setups may not cover. I am interested in conducting simulation studies [6]
            to explore how phenomena surrounding bias-propagation such as information cascades may show up in multi-agent systems and their resultant effects on decision-making.
        </blockquote>
    While my research experiences on biases and ethics were not directly related to my main research interest surrounding AI security, I was still able to tie them in through my future directions; the goal here was recall optimization again; I wanted to appeal to professors who started exploring AI-safety and risks from the angle of social biases. 
    <blockquote>
        <b>Vision for graduate school</b>: Pursuing a Ph.D. at <b>X</b> will equip me to
        address these challenges and contribute meaningfully to AI safety and security, and prepare
        me for a research-focussed career. I'm interested to work with <b>Y</b>; her focus
        on <b>ABC</b> aligns strongly with my current interests around the problem. Given my background in AI ethics and safety, I believe I am
        well-positioned to examine both representational and generational harms that AI systems
        can produce. To this end, Prof. <b>Z's</b> research vision of <b>DEF</b> aligns deeply with my research goals during my
        graduate studies. Notably, her projects on <b>GHI</b> overlap with a broad set of problems I wish to pursue. Overall, <b>X</b> is a great
        place for me to pursue my research aspirations, as I can learn from its diverse student group and esteemed faculty.
    </blockquote>
    This final paragraph is rather standard in most SoPs - you need to specify why you're applying to this specific institution, why it's a good fit, and who you wish to work with. 
    I made sure to clearly specify how my research interests aligned with the professors I was applying to work with, and how their research aligned with my goals.
    Note that I was intentionally vague about what I wanted to do with my PhD - this was in part because I wasn't too sure of it myself. But I was leaning towards heading back to the industry. 
    I would recommend being more open and specific about this; as all of my interviewers (I had 10!) asked me about my future career plans.

    </pre>  
    </article>
</body>
    <script>
        function toggleContrast() {
            document.documentElement.classList.toggle('contrast');
        }

        function toggleInvert() {
            document.documentElement.classList.toggle('inverted');
        }
    </script>
</html>